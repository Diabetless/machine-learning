{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4VXm60U4RSN"
      },
      "source": [
        "# Load Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGwUjwgsnlIs"
      },
      "source": [
        "## Download Dataset from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arQfHRxPnO0i",
        "outputId": "5badc568-144e-4988-f7e4-3957653af108"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=186HlpFc60T0jWYrJPodAJNtYK6Hgr2tg\n",
            "To: /content/datasets.zip\n",
            "100% 187M/187M [00:02<00:00, 78.6MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown 186HlpFc60T0jWYrJPodAJNtYK6Hgr2tg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7Ts8aVZn2xw"
      },
      "source": [
        "## Unzip dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgmU6-jjn4XE"
      },
      "outputs": [],
      "source": [
        "!unzip -q datasets.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1t63dV764GXk"
      },
      "source": [
        "## Remove Zip file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DwWY9ypioGth"
      },
      "outputs": [],
      "source": [
        "!rm datasets.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwU8mQxQ4Za8"
      },
      "source": [
        "# Install Required Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kvcd2ZB139z8",
        "outputId": "a58b954e-e3d3-4e31-b553-a7e32fc41188"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.0.208-py3-none-any.whl (645 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/645.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.4/645.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m645.2/645.2 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.22.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.23.5)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.16.0+cu118)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.1)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.5.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.12.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Collecting thop>=0.1.1 (from ultralytics)\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.44.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2023.7.22)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Installing collected packages: thop, ultralytics\n",
            "Successfully installed thop-0.1.1.post2209072238 ultralytics-8.0.208\n"
          ]
        }
      ],
      "source": [
        "%pip install ultralytics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vae28lfa4lrO"
      },
      "source": [
        "# Import Necessary Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lPIcDkdQ4B8p"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFZ9p-144t_v"
      },
      "source": [
        "# Instantiate Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otwLWp2Z4EVX",
        "outputId": "44322585-fda3-4968-928c-91959df0a6ad"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8s.pt to 'yolov8s.pt'...\n",
            "100%|██████████| 21.5M/21.5M [00:00<00:00, 399MB/s]\n",
            "layer                                     name  gradient   parameters                shape         mu      sigma\n",
            "    0                      model.0.conv.weight     False          864        [32, 3, 3, 3]   -0.00203       0.13 torch.float32\n",
            "    1                        model.0.bn.weight     False           32                 [32]        3.5          1 torch.float32\n",
            "    2                          model.0.bn.bias     False           32                 [32]     -0.613       2.97 torch.float32\n",
            "    3                      model.1.conv.weight     False        18432       [64, 32, 3, 3]  -0.000742     0.0358 torch.float32\n",
            "    4                        model.1.bn.weight     False           64                 [64]       3.37      0.704 torch.float32\n",
            "    5                          model.1.bn.bias     False           64                 [64]      0.439       1.18 torch.float32\n",
            "    6                  model.2.cv1.conv.weight     False         4096       [64, 64, 1, 1]   -0.00687     0.0533 torch.float32\n",
            "    7                    model.2.cv1.bn.weight     False           64                 [64]        1.8       0.95 torch.float32\n",
            "    8                      model.2.cv1.bn.bias     False           64                 [64]      0.392       1.37 torch.float32\n",
            "    9                  model.2.cv2.conv.weight     False         6144       [64, 96, 1, 1]   -0.00341     0.0475 torch.float32\n",
            "   10                    model.2.cv2.bn.weight     False           64                 [64]       1.21       0.35 torch.float32\n",
            "   11                      model.2.cv2.bn.bias     False           64                 [64]   -0.00756      0.724 torch.float32\n",
            "   12              model.2.m.0.cv1.conv.weight     False         9216       [32, 32, 3, 3]   -0.00135     0.0348 torch.float32\n",
            "   13                model.2.m.0.cv1.bn.weight     False           32                 [32]        2.2       0.57 torch.float32\n",
            "   14                  model.2.m.0.cv1.bn.bias     False           32                 [32]       0.42       1.44 torch.float32\n",
            "   15              model.2.m.0.cv2.conv.weight     False         9216       [32, 32, 3, 3]   -0.00147     0.0318 torch.float32\n",
            "   16                model.2.m.0.cv2.bn.weight     False           32                 [32]       1.77      0.542 torch.float32\n",
            "   17                  model.2.m.0.cv2.bn.bias     False           32                 [32]      0.829       1.43 torch.float32\n",
            "   18                      model.3.conv.weight     False        73728      [128, 64, 3, 3]     -0.001     0.0189 torch.float32\n",
            "   19                        model.3.bn.weight     False          128                [128]      0.829      0.203 torch.float32\n",
            "   20                          model.3.bn.bias     False          128                [128]     -0.269      0.722 torch.float32\n",
            "   21                  model.4.cv1.conv.weight     False        16384     [128, 128, 1, 1]   -0.00212      0.032 torch.float32\n",
            "   22                    model.4.cv1.bn.weight     False          128                [128]      0.821      0.372 torch.float32\n",
            "   23                      model.4.cv1.bn.bias     False          128                [128]      0.025      0.669 torch.float32\n",
            "   24                  model.4.cv2.conv.weight     False        32768     [128, 256, 1, 1]   -0.00172     0.0265 torch.float32\n",
            "   25                    model.4.cv2.bn.weight     False          128                [128]      0.911      0.219 torch.float32\n",
            "   26                      model.4.cv2.bn.bias     False          128                [128]     -0.463      0.702 torch.float32\n",
            "   27              model.4.m.0.cv1.conv.weight     False        36864       [64, 64, 3, 3]   -0.00104     0.0201 torch.float32\n",
            "   28                model.4.m.0.cv1.bn.weight     False           64                 [64]      0.889      0.183 torch.float32\n",
            "   29                  model.4.m.0.cv1.bn.bias     False           64                 [64]      -0.69      0.676 torch.float32\n",
            "   30              model.4.m.0.cv2.conv.weight     False        36864       [64, 64, 3, 3]   -0.00102     0.0185 torch.float32\n",
            "   31                model.4.m.0.cv2.bn.weight     False           64                 [64]      0.775      0.208 torch.float32\n",
            "   32                  model.4.m.0.cv2.bn.bias     False           64                 [64]     -0.117      0.606 torch.float32\n",
            "   33              model.4.m.1.cv1.conv.weight     False        36864       [64, 64, 3, 3]   -0.00141     0.0184 torch.float32\n",
            "   34                model.4.m.1.cv1.bn.weight     False           64                 [64]      0.771      0.104 torch.float32\n",
            "   35                  model.4.m.1.cv1.bn.bias     False           64                 [64]      -1.04      0.563 torch.float32\n",
            "   36              model.4.m.1.cv2.conv.weight     False        36864       [64, 64, 3, 3]  -0.000975     0.0175 torch.float32\n",
            "   37                model.4.m.1.cv2.bn.weight     False           64                 [64]       1.08      0.266 torch.float32\n",
            "   38                  model.4.m.1.cv2.bn.bias     False           64                 [64]      0.226      0.684 torch.float32\n",
            "   39                      model.5.conv.weight     False       294912     [256, 128, 3, 3]  -0.000185     0.0112 torch.float32\n",
            "   40                        model.5.bn.weight     False          256                [256]      0.891      0.185 torch.float32\n",
            "   41                          model.5.bn.bias     False          256                [256]      -0.55      0.556 torch.float32\n",
            "   42                  model.6.cv1.conv.weight     False        65536     [256, 256, 1, 1]   -0.00173     0.0197 torch.float32\n",
            "   43                    model.6.cv1.bn.weight     False          256                [256]      0.998      0.367 torch.float32\n",
            "   44                      model.6.cv1.bn.bias     False          256                [256]     -0.296      0.579 torch.float32\n",
            "   45                  model.6.cv2.conv.weight     False       131072     [256, 512, 1, 1]   -0.00112     0.0165 torch.float32\n",
            "   46                    model.6.cv2.bn.weight     False          256                [256]      0.936      0.183 torch.float32\n",
            "   47                      model.6.cv2.bn.bias     False          256                [256]     -0.885      0.624 torch.float32\n",
            "   48              model.6.m.0.cv1.conv.weight     False       147456     [128, 128, 3, 3]  -0.000907     0.0117 torch.float32\n",
            "   49                model.6.m.0.cv1.bn.weight     False          128                [128]       1.07      0.145 torch.float32\n",
            "   50                  model.6.m.0.cv1.bn.bias     False          128                [128]      -1.11      0.461 torch.float32\n",
            "   51              model.6.m.0.cv2.conv.weight     False       147456     [128, 128, 3, 3]  -0.000819     0.0114 torch.float32\n",
            "   52                model.6.m.0.cv2.bn.weight     False          128                [128]      0.916      0.203 torch.float32\n",
            "   53                  model.6.m.0.cv2.bn.bias     False          128                [128]     -0.376      0.483 torch.float32\n",
            "   54              model.6.m.1.cv1.conv.weight     False       147456     [128, 128, 3, 3]  -0.000845     0.0118 torch.float32\n",
            "   55                model.6.m.1.cv1.bn.weight     False          128                [128]      0.965      0.127 torch.float32\n",
            "   56                  model.6.m.1.cv1.bn.bias     False          128                [128]      -1.26      0.558 torch.float32\n",
            "   57              model.6.m.1.cv2.conv.weight     False       147456     [128, 128, 3, 3]  -0.000596     0.0111 torch.float32\n",
            "   58                model.6.m.1.cv2.bn.weight     False          128                [128]        1.4      0.221 torch.float32\n",
            "   59                  model.6.m.1.cv2.bn.bias     False          128                [128]     -0.157      0.505 torch.float32\n",
            "   60                      model.7.conv.weight     False  1.17965e+06     [512, 256, 3, 3]  -0.000377    0.00686 torch.float32\n",
            "   61                        model.7.bn.weight     False          512                [512]        1.1       0.13 torch.float32\n",
            "   62                          model.7.bn.bias     False          512                [512]     -0.844      0.247 torch.float32\n",
            "   63                  model.8.cv1.conv.weight     False       262144     [512, 512, 1, 1]   -0.00155     0.0123 torch.float32\n",
            "   64                    model.8.cv1.bn.weight     False          512                [512]       1.11      0.199 torch.float32\n",
            "   65                      model.8.cv1.bn.bias     False          512                [512]     -0.838      0.513 torch.float32\n",
            "   66                  model.8.cv2.conv.weight     False       393216     [512, 768, 1, 1]     -0.001     0.0104 torch.float32\n",
            "   67                    model.8.cv2.bn.weight     False          512                [512]       1.24      0.163 torch.float32\n",
            "   68                      model.8.cv2.bn.bias     False          512                [512]     -0.726      0.279 torch.float32\n",
            "   69              model.8.m.0.cv1.conv.weight     False       589824     [256, 256, 3, 3]  -0.000453    0.00786 torch.float32\n",
            "   70                model.8.m.0.cv1.bn.weight     False          256                [256]       1.23      0.146 torch.float32\n",
            "   71                  model.8.m.0.cv1.bn.bias     False          256                [256]      -1.01      0.484 torch.float32\n",
            "   72              model.8.m.0.cv2.conv.weight     False       589824     [256, 256, 3, 3]  -0.000633    0.00759 torch.float32\n",
            "   73                model.8.m.0.cv2.bn.weight     False          256                [256]       1.62      0.245 torch.float32\n",
            "   74                  model.8.m.0.cv2.bn.bias     False          256                [256]     -0.572      0.319 torch.float32\n",
            "   75                  model.9.cv1.conv.weight     False       131072     [256, 512, 1, 1]   -0.00229     0.0148 torch.float32\n",
            "   76                    model.9.cv1.bn.weight     False          256                [256]      0.944      0.196 torch.float32\n",
            "   77                      model.9.cv1.bn.bias     False          256                [256]      0.786      0.438 torch.float32\n",
            "   78                  model.9.cv2.conv.weight     False       524288    [512, 1024, 1, 1]  -1.53e-05    0.00963 torch.float32\n",
            "   79                    model.9.cv2.bn.weight     False          512                [512]      0.982      0.174 torch.float32\n",
            "   80                      model.9.cv2.bn.bias     False          512                [512]      -1.31      0.509 torch.float32\n",
            "   81                 model.12.cv1.conv.weight     False       196608     [256, 768, 1, 1]   -0.00129     0.0153 torch.float32\n",
            "   82                   model.12.cv1.bn.weight     False          256                [256]          1      0.212 torch.float32\n",
            "   83                     model.12.cv1.bn.bias     False          256                [256]     -0.747      0.686 torch.float32\n",
            "   84                 model.12.cv2.conv.weight     False        98304     [256, 384, 1, 1]   -0.00224     0.0165 torch.float32\n",
            "   85                   model.12.cv2.bn.weight     False          256                [256]       0.89      0.201 torch.float32\n",
            "   86                     model.12.cv2.bn.bias     False          256                [256]     -0.598      0.554 torch.float32\n",
            "   87             model.12.m.0.cv1.conv.weight     False       147456     [128, 128, 3, 3]   -0.00102     0.0122 torch.float32\n",
            "   88               model.12.m.0.cv1.bn.weight     False          128                [128]      0.949      0.138 torch.float32\n",
            "   89                 model.12.m.0.cv1.bn.bias     False          128                [128]     -0.997       0.52 torch.float32\n",
            "   90             model.12.m.0.cv2.conv.weight     False       147456     [128, 128, 3, 3]  -0.000695     0.0112 torch.float32\n",
            "   91               model.12.m.0.cv2.bn.weight     False          128                [128]      0.956      0.135 torch.float32\n",
            "   92                 model.12.m.0.cv2.bn.bias     False          128                [128]     -0.455      0.485 torch.float32\n",
            "   93                 model.15.cv1.conv.weight     False        49152     [128, 384, 1, 1]   -0.00122     0.0194 torch.float32\n",
            "   94                   model.15.cv1.bn.weight     False          128                [128]      0.612      0.214 torch.float32\n",
            "   95                     model.15.cv1.bn.bias     False          128                [128]     -0.276      0.804 torch.float32\n",
            "   96                 model.15.cv2.conv.weight     False        24576     [128, 192, 1, 1]   -0.00125     0.0214 torch.float32\n",
            "   97                   model.15.cv2.bn.weight     False          128                [128]      0.609       0.26 torch.float32\n",
            "   98                     model.15.cv2.bn.bias     False          128                [128]     -0.377      0.751 torch.float32\n",
            "   99             model.15.m.0.cv1.conv.weight     False        36864       [64, 64, 3, 3]   -0.00126     0.0178 torch.float32\n",
            "  100               model.15.m.0.cv1.bn.weight     False           64                 [64]      0.775      0.123 torch.float32\n",
            "  101                 model.15.m.0.cv1.bn.bias     False           64                 [64]     -0.726      0.592 torch.float32\n",
            "  102             model.15.m.0.cv2.conv.weight     False        36864       [64, 64, 3, 3]   -0.00112     0.0167 torch.float32\n",
            "  103               model.15.m.0.cv2.bn.weight     False           64                 [64]      0.856      0.187 torch.float32\n",
            "  104                 model.15.m.0.cv2.bn.bias     False           64                 [64]     -0.247       0.61 torch.float32\n",
            "  105                     model.16.conv.weight     False       147456     [128, 128, 3, 3]  -0.000348    0.00818 torch.float32\n",
            "  106                       model.16.bn.weight     False          128                [128]       0.97      0.194 torch.float32\n",
            "  107                         model.16.bn.bias     False          128                [128]     -0.493      0.392 torch.float32\n",
            "  108                 model.18.cv1.conv.weight     False        98304     [256, 384, 1, 1]  -0.000932     0.0126 torch.float32\n",
            "  109                   model.18.cv1.bn.weight     False          256                [256]      0.938       0.16 torch.float32\n",
            "  110                     model.18.cv1.bn.bias     False          256                [256]     -0.487      0.451 torch.float32\n",
            "  111                 model.18.cv2.conv.weight     False        98304     [256, 384, 1, 1]   -0.00102     0.0117 torch.float32\n",
            "  112                   model.18.cv2.bn.weight     False          256                [256]      0.882      0.299 torch.float32\n",
            "  113                     model.18.cv2.bn.bias     False          256                [256]     -0.727      0.527 torch.float32\n",
            "  114             model.18.m.0.cv1.conv.weight     False       147456     [128, 128, 3, 3]  -0.000797    0.00972 torch.float32\n",
            "  115               model.18.m.0.cv1.bn.weight     False          128                [128]      0.841      0.163 torch.float32\n",
            "  116                 model.18.m.0.cv1.bn.bias     False          128                [128]      -0.98      0.525 torch.float32\n",
            "  117             model.18.m.0.cv2.conv.weight     False       147456     [128, 128, 3, 3]  -0.000474    0.00897 torch.float32\n",
            "  118               model.18.m.0.cv2.bn.weight     False          128                [128]        1.3      0.232 torch.float32\n",
            "  119                 model.18.m.0.cv2.bn.bias     False          128                [128]     -0.405      0.492 torch.float32\n",
            "  120                     model.19.conv.weight     False       589824     [256, 256, 3, 3]  -0.000215    0.00424 torch.float32\n",
            "  121                       model.19.bn.weight     False          256                [256]      0.897      0.161 torch.float32\n",
            "  122                         model.19.bn.bias     False          256                [256]     -0.533      0.201 torch.float32\n",
            "  123                 model.21.cv1.conv.weight     False       393216     [512, 768, 1, 1]  -0.000583    0.00717 torch.float32\n",
            "  124                   model.21.cv1.bn.weight     False          512                [512]       1.02      0.169 torch.float32\n",
            "  125                     model.21.cv1.bn.bias     False          512                [512]      -0.61      0.349 torch.float32\n",
            "  126                 model.21.cv2.conv.weight     False       393216     [512, 768, 1, 1]  -0.000541    0.00586 torch.float32\n",
            "  127                   model.21.cv2.bn.weight     False          512                [512]       1.12       0.24 torch.float32\n",
            "  128                     model.21.cv2.bn.bias     False          512                [512]     -0.669      0.276 torch.float32\n",
            "  129             model.21.m.0.cv1.conv.weight     False       589824     [256, 256, 3, 3]  -0.000351    0.00483 torch.float32\n",
            "  130               model.21.m.0.cv1.bn.weight     False          256                [256]       1.04      0.169 torch.float32\n",
            "  131                 model.21.m.0.cv1.bn.bias     False          256                [256]     -0.869      0.358 torch.float32\n",
            "  132             model.21.m.0.cv2.conv.weight     False       589824     [256, 256, 3, 3]   -0.00025    0.00449 torch.float32\n",
            "  133               model.21.m.0.cv2.bn.weight     False          256                [256]       1.33      0.188 torch.float32\n",
            "  134                 model.21.m.0.cv2.bn.bias     False          256                [256]     -0.583      0.302 torch.float32\n",
            "  135             model.22.cv2.0.0.conv.weight     False        73728      [64, 128, 3, 3]  -0.000563    0.00969 torch.float32\n",
            "  136               model.22.cv2.0.0.bn.weight     False           64                 [64]       1.01      0.361 torch.float32\n",
            "  137                 model.22.cv2.0.0.bn.bias     False           64                 [64]     -0.214      0.717 torch.float32\n",
            "  138             model.22.cv2.0.1.conv.weight     False        36864       [64, 64, 3, 3]  -0.000354     0.0114 torch.float32\n",
            "  139               model.22.cv2.0.1.bn.weight     False           64                 [64]       2.34       1.03 torch.float32\n",
            "  140                 model.22.cv2.0.1.bn.bias     False           64                 [64]       1.01      0.623 torch.float32\n",
            "  141                  model.22.cv2.0.2.weight     False         4096       [64, 64, 1, 1]   2.39e-06     0.0462 torch.float32\n",
            "  142                    model.22.cv2.0.2.bias     False           64                 [64]          1       1.39 torch.float32\n",
            "  143             model.22.cv2.1.0.conv.weight     False       147456      [64, 256, 3, 3]  -0.000253    0.00663 torch.float32\n",
            "  144               model.22.cv2.1.0.bn.weight     False           64                 [64]       1.17      0.409 torch.float32\n",
            "  145                 model.22.cv2.1.0.bn.bias     False           64                 [64]     -0.108      0.676 torch.float32\n",
            "  146             model.22.cv2.1.1.conv.weight     False        36864       [64, 64, 3, 3]  -0.000268      0.011 torch.float32\n",
            "  147               model.22.cv2.1.1.bn.weight     False           64                 [64]       2.47      0.871 torch.float32\n",
            "  148                 model.22.cv2.1.1.bn.bias     False           64                 [64]      0.817      0.535 torch.float32\n",
            "  149                  model.22.cv2.1.2.weight     False         4096       [64, 64, 1, 1]  -2.78e-07     0.0523 torch.float32\n",
            "  150                    model.22.cv2.1.2.bias     False           64                 [64]          1       1.35 torch.float32\n",
            "  151             model.22.cv2.2.0.conv.weight     False       294912      [64, 512, 3, 3]  -0.000161    0.00459 torch.float32\n",
            "  152               model.22.cv2.2.0.bn.weight     False           64                 [64]       1.45      0.336 torch.float32\n",
            "  153                 model.22.cv2.2.0.bn.bias     False           64                 [64]     -0.268      0.598 torch.float32\n",
            "  154             model.22.cv2.2.1.conv.weight     False        36864       [64, 64, 3, 3]    -0.0003    0.00989 torch.float32\n",
            "  155               model.22.cv2.2.1.bn.weight     False           64                 [64]       2.96      0.747 torch.float32\n",
            "  156                 model.22.cv2.2.1.bn.bias     False           64                 [64]      0.853      0.566 torch.float32\n",
            "  157                  model.22.cv2.2.2.weight     False         4096       [64, 64, 1, 1]   3.86e-06     0.0557 torch.float32\n",
            "  158                    model.22.cv2.2.2.bias     False           64                 [64]          1       1.26 torch.float32\n",
            "  159             model.22.cv3.0.0.conv.weight     False       147456     [128, 128, 3, 3]  -0.000545     0.0069 torch.float32\n",
            "  160               model.22.cv3.0.0.bn.weight     False          128                [128]      0.825      0.282 torch.float32\n",
            "  161                 model.22.cv3.0.0.bn.bias     False          128                [128]     -0.442      0.622 torch.float32\n",
            "  162             model.22.cv3.0.1.conv.weight     False       147456     [128, 128, 3, 3]   -0.00063    0.00624 torch.float32\n",
            "  163               model.22.cv3.0.1.bn.weight     False          128                [128]       2.31      0.624 torch.float32\n",
            "  164                 model.22.cv3.0.1.bn.bias     False          128                [128]       1.17       1.32 torch.float32\n",
            "  165                  model.22.cv3.0.2.weight     False        10240      [80, 128, 1, 1]   -0.00936     0.0382 torch.float32\n",
            "  166                    model.22.cv3.0.2.bias     False           80                 [80]      -11.4       1.07 torch.float32\n",
            "  167             model.22.cv3.1.0.conv.weight     False       294912     [128, 256, 3, 3]  -0.000266    0.00505 torch.float32\n",
            "  168               model.22.cv3.1.0.bn.weight     False          128                [128]       1.02      0.302 torch.float32\n",
            "  169                 model.22.cv3.1.0.bn.bias     False          128                [128]     -0.306      0.741 torch.float32\n",
            "  170             model.22.cv3.1.1.conv.weight     False       147456     [128, 128, 3, 3]  -0.000671    0.00575 torch.float32\n",
            "  171               model.22.cv3.1.1.bn.weight     False          128                [128]       2.41      0.989 torch.float32\n",
            "  172                 model.22.cv3.1.1.bn.bias     False          128                [128]       1.05       1.12 torch.float32\n",
            "  173                  model.22.cv3.1.2.weight     False        10240      [80, 128, 1, 1]   -0.00853     0.0381 torch.float32\n",
            "  174                    model.22.cv3.1.2.bias     False           80                 [80]      -10.5      0.859 torch.float32\n",
            "  175             model.22.cv3.2.0.conv.weight     False       589824     [128, 512, 3, 3]  -0.000144    0.00348 torch.float32\n",
            "  176               model.22.cv3.2.0.bn.weight     False          128                [128]       1.17      0.273 torch.float32\n",
            "  177                 model.22.cv3.2.0.bn.bias     False          128                [128]     -0.402      0.653 torch.float32\n",
            "  178             model.22.cv3.2.1.conv.weight     False       147456     [128, 128, 3, 3]  -0.000624    0.00504 torch.float32\n",
            "  179               model.22.cv3.2.1.bn.weight     False          128                [128]       2.64      0.963 torch.float32\n",
            "  180                 model.22.cv3.2.1.bn.bias     False          128                [128]      0.946       1.14 torch.float32\n",
            "  181                  model.22.cv3.2.2.weight     False        10240      [80, 128, 1, 1]   -0.00716     0.0364 torch.float32\n",
            "  182                    model.22.cv3.2.2.bias     False           80                 [80]      -9.63      0.843 torch.float32\n",
            "  183                 model.22.dfl.conv.weight     False           16        [1, 16, 1, 1]        7.5       4.76 torch.float32\n",
            "YOLOv8s summary: 225 layers, 11166560 parameters, 0 gradients, 28.8 GFLOPs\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(225, 11166560, 0, 28.816844800000002)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Change the argument based on your experimental\n",
        "model = YOLO('yolov8s.pt')\n",
        "model.info(detailed=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2Bg3-UEhWK8",
        "outputId": "754b7ed4-c270-40dd-f8c8-be7488812c29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1blF8nj8UZ1Hq-UVs8TP1fsQ3WfheaNYq\n",
            "To: /content/data.yaml\n",
            "\r  0% 0.00/244 [00:00<?, ?B/s]\r100% 244/244 [00:00<00:00, 1.31MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown 1blF8nj8UZ1Hq-UVs8TP1fsQ3WfheaNYq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-tPD4aS4tk3"
      },
      "outputs": [],
      "source": [
        "!mkdir results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BnuZoDQ84um9"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "batches = [4, 8, 16]\n",
        "lrs = ['1e-2', '1e-3',' 1e-4']\n",
        "\n",
        "for batch in batches:\n",
        "  for lr in lrs:\n",
        "    model = YOLO('yolov8s.pt')\n",
        "    model_name = f'tuning_model_batch-{batch}_lr-{lr}'\n",
        "    model.train(\n",
        "        data='./data.yaml',\n",
        "        epochs=10,\n",
        "        batch=batch,\n",
        "        imgsz=512,\n",
        "        name=model_name,\n",
        "        optimizer='Adamax',\n",
        "        lr0=float(lr)\n",
        "    )\n",
        "    RESULT_PATH = f'./runs/detect/{model_name}/results.csv'\n",
        "    shutil.copy(RESULT_PATH, f'./results/results_batch-{batch}_lr-{lr}.csv')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
