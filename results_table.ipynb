{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constant Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTIMIZERS = 'Adamax'\n",
    "MEDIUM_RES_PATH = os.path.join(OPTIMIZERS, './model_medium_res/')\n",
    "SMALL_RES_PATH = os.path.join(OPTIMIZERS, './model_small_res/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medium Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "medium_last_res = []\n",
    "\n",
    "for filename in os.listdir(MEDIUM_RES_PATH):\n",
    "    df = pd.read_csv(os.path.join(MEDIUM_RES_PATH, filename))\n",
    "    df = df.iloc[-1, 1:-3]\n",
    "    batch, lr = tuple(filename.split('_')[1:])\n",
    "    df.name = 'Batch: {} | Learning Rate: {}'.format(batch.split('-')[1], float(lr[3:-4]))\n",
    "    medium_last_res.append(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train/box_loss</th>\n",
       "      <th>train/cls_loss</th>\n",
       "      <th>train/dfl_loss</th>\n",
       "      <th>metrics/precision(B)</th>\n",
       "      <th>metrics/recall(B)</th>\n",
       "      <th>metrics/mAP50(B)</th>\n",
       "      <th>metrics/mAP50-95(B)</th>\n",
       "      <th>val/box_loss</th>\n",
       "      <th>val/cls_loss</th>\n",
       "      <th>val/dfl_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Batch: 16 | Learning Rate: 0.01</th>\n",
       "      <td>1.11970</td>\n",
       "      <td>1.37820</td>\n",
       "      <td>1.5017</td>\n",
       "      <td>0.70772</td>\n",
       "      <td>0.54868</td>\n",
       "      <td>0.64879</td>\n",
       "      <td>0.44796</td>\n",
       "      <td>1.15740</td>\n",
       "      <td>1.34790</td>\n",
       "      <td>1.5252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch: 16 | Learning Rate: 0.001</th>\n",
       "      <td>0.83858</td>\n",
       "      <td>0.64584</td>\n",
       "      <td>1.2547</td>\n",
       "      <td>0.86802</td>\n",
       "      <td>0.84658</td>\n",
       "      <td>0.90637</td>\n",
       "      <td>0.68719</td>\n",
       "      <td>0.96654</td>\n",
       "      <td>0.67574</td>\n",
       "      <td>1.3317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch: 16 | Learning Rate: 0.0001</th>\n",
       "      <td>0.78865</td>\n",
       "      <td>0.59147</td>\n",
       "      <td>1.2010</td>\n",
       "      <td>0.86128</td>\n",
       "      <td>0.83888</td>\n",
       "      <td>0.90910</td>\n",
       "      <td>0.68967</td>\n",
       "      <td>0.93589</td>\n",
       "      <td>0.67070</td>\n",
       "      <td>1.2906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch: 4 | Learning Rate: 0.01</th>\n",
       "      <td>1.14990</td>\n",
       "      <td>1.78480</td>\n",
       "      <td>1.6006</td>\n",
       "      <td>0.55154</td>\n",
       "      <td>0.53087</td>\n",
       "      <td>0.58194</td>\n",
       "      <td>0.40394</td>\n",
       "      <td>1.17260</td>\n",
       "      <td>1.54450</td>\n",
       "      <td>1.5822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch: 4 | Learning Rate: 0.001</th>\n",
       "      <td>0.87489</td>\n",
       "      <td>0.77081</td>\n",
       "      <td>1.3280</td>\n",
       "      <td>0.84575</td>\n",
       "      <td>0.78966</td>\n",
       "      <td>0.87373</td>\n",
       "      <td>0.62910</td>\n",
       "      <td>1.01150</td>\n",
       "      <td>0.79194</td>\n",
       "      <td>1.4209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch: 4 | Learning Rate: 0.0001</th>\n",
       "      <td>0.83771</td>\n",
       "      <td>0.74074</td>\n",
       "      <td>1.2792</td>\n",
       "      <td>0.83033</td>\n",
       "      <td>0.82433</td>\n",
       "      <td>0.87450</td>\n",
       "      <td>0.64690</td>\n",
       "      <td>0.96515</td>\n",
       "      <td>0.75244</td>\n",
       "      <td>1.3583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch: 8 | Learning Rate: 0.01</th>\n",
       "      <td>1.14460</td>\n",
       "      <td>1.51430</td>\n",
       "      <td>1.5350</td>\n",
       "      <td>0.60155</td>\n",
       "      <td>0.61165</td>\n",
       "      <td>0.64898</td>\n",
       "      <td>0.43381</td>\n",
       "      <td>1.18990</td>\n",
       "      <td>1.36060</td>\n",
       "      <td>1.5483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch: 8 | Learning Rate: 0.001</th>\n",
       "      <td>0.85424</td>\n",
       "      <td>0.71114</td>\n",
       "      <td>1.2847</td>\n",
       "      <td>0.81815</td>\n",
       "      <td>0.85556</td>\n",
       "      <td>0.89363</td>\n",
       "      <td>0.66847</td>\n",
       "      <td>1.00120</td>\n",
       "      <td>0.73124</td>\n",
       "      <td>1.3812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch: 8 | Learning Rate: 0.0001</th>\n",
       "      <td>0.81298</td>\n",
       "      <td>0.65327</td>\n",
       "      <td>1.2454</td>\n",
       "      <td>0.85181</td>\n",
       "      <td>0.84980</td>\n",
       "      <td>0.89545</td>\n",
       "      <td>0.67108</td>\n",
       "      <td>0.94756</td>\n",
       "      <td>0.70645</td>\n",
       "      <td>1.3182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            train/box_loss  \\\n",
       "Batch: 16 | Learning Rate: 0.01                    1.11970   \n",
       "Batch: 16 | Learning Rate: 0.001                   0.83858   \n",
       "Batch: 16 | Learning Rate: 0.0001                  0.78865   \n",
       "Batch: 4 | Learning Rate: 0.01                     1.14990   \n",
       "Batch: 4 | Learning Rate: 0.001                    0.87489   \n",
       "Batch: 4 | Learning Rate: 0.0001                   0.83771   \n",
       "Batch: 8 | Learning Rate: 0.01                     1.14460   \n",
       "Batch: 8 | Learning Rate: 0.001                    0.85424   \n",
       "Batch: 8 | Learning Rate: 0.0001                   0.81298   \n",
       "\n",
       "                                            train/cls_loss  \\\n",
       "Batch: 16 | Learning Rate: 0.01                    1.37820   \n",
       "Batch: 16 | Learning Rate: 0.001                   0.64584   \n",
       "Batch: 16 | Learning Rate: 0.0001                  0.59147   \n",
       "Batch: 4 | Learning Rate: 0.01                     1.78480   \n",
       "Batch: 4 | Learning Rate: 0.001                    0.77081   \n",
       "Batch: 4 | Learning Rate: 0.0001                   0.74074   \n",
       "Batch: 8 | Learning Rate: 0.01                     1.51430   \n",
       "Batch: 8 | Learning Rate: 0.001                    0.71114   \n",
       "Batch: 8 | Learning Rate: 0.0001                   0.65327   \n",
       "\n",
       "                                            train/dfl_loss  \\\n",
       "Batch: 16 | Learning Rate: 0.01                     1.5017   \n",
       "Batch: 16 | Learning Rate: 0.001                    1.2547   \n",
       "Batch: 16 | Learning Rate: 0.0001                   1.2010   \n",
       "Batch: 4 | Learning Rate: 0.01                      1.6006   \n",
       "Batch: 4 | Learning Rate: 0.001                     1.3280   \n",
       "Batch: 4 | Learning Rate: 0.0001                    1.2792   \n",
       "Batch: 8 | Learning Rate: 0.01                      1.5350   \n",
       "Batch: 8 | Learning Rate: 0.001                     1.2847   \n",
       "Batch: 8 | Learning Rate: 0.0001                    1.2454   \n",
       "\n",
       "                                      metrics/precision(B)  \\\n",
       "Batch: 16 | Learning Rate: 0.01                    0.70772   \n",
       "Batch: 16 | Learning Rate: 0.001                   0.86802   \n",
       "Batch: 16 | Learning Rate: 0.0001                  0.86128   \n",
       "Batch: 4 | Learning Rate: 0.01                     0.55154   \n",
       "Batch: 4 | Learning Rate: 0.001                    0.84575   \n",
       "Batch: 4 | Learning Rate: 0.0001                   0.83033   \n",
       "Batch: 8 | Learning Rate: 0.01                     0.60155   \n",
       "Batch: 8 | Learning Rate: 0.001                    0.81815   \n",
       "Batch: 8 | Learning Rate: 0.0001                   0.85181   \n",
       "\n",
       "                                         metrics/recall(B)  \\\n",
       "Batch: 16 | Learning Rate: 0.01                    0.54868   \n",
       "Batch: 16 | Learning Rate: 0.001                   0.84658   \n",
       "Batch: 16 | Learning Rate: 0.0001                  0.83888   \n",
       "Batch: 4 | Learning Rate: 0.01                     0.53087   \n",
       "Batch: 4 | Learning Rate: 0.001                    0.78966   \n",
       "Batch: 4 | Learning Rate: 0.0001                   0.82433   \n",
       "Batch: 8 | Learning Rate: 0.01                     0.61165   \n",
       "Batch: 8 | Learning Rate: 0.001                    0.85556   \n",
       "Batch: 8 | Learning Rate: 0.0001                   0.84980   \n",
       "\n",
       "                                          metrics/mAP50(B)  \\\n",
       "Batch: 16 | Learning Rate: 0.01                    0.64879   \n",
       "Batch: 16 | Learning Rate: 0.001                   0.90637   \n",
       "Batch: 16 | Learning Rate: 0.0001                  0.90910   \n",
       "Batch: 4 | Learning Rate: 0.01                     0.58194   \n",
       "Batch: 4 | Learning Rate: 0.001                    0.87373   \n",
       "Batch: 4 | Learning Rate: 0.0001                   0.87450   \n",
       "Batch: 8 | Learning Rate: 0.01                     0.64898   \n",
       "Batch: 8 | Learning Rate: 0.001                    0.89363   \n",
       "Batch: 8 | Learning Rate: 0.0001                   0.89545   \n",
       "\n",
       "                                       metrics/mAP50-95(B)  \\\n",
       "Batch: 16 | Learning Rate: 0.01                    0.44796   \n",
       "Batch: 16 | Learning Rate: 0.001                   0.68719   \n",
       "Batch: 16 | Learning Rate: 0.0001                  0.68967   \n",
       "Batch: 4 | Learning Rate: 0.01                     0.40394   \n",
       "Batch: 4 | Learning Rate: 0.001                    0.62910   \n",
       "Batch: 4 | Learning Rate: 0.0001                   0.64690   \n",
       "Batch: 8 | Learning Rate: 0.01                     0.43381   \n",
       "Batch: 8 | Learning Rate: 0.001                    0.66847   \n",
       "Batch: 8 | Learning Rate: 0.0001                   0.67108   \n",
       "\n",
       "                                              val/box_loss  \\\n",
       "Batch: 16 | Learning Rate: 0.01                    1.15740   \n",
       "Batch: 16 | Learning Rate: 0.001                   0.96654   \n",
       "Batch: 16 | Learning Rate: 0.0001                  0.93589   \n",
       "Batch: 4 | Learning Rate: 0.01                     1.17260   \n",
       "Batch: 4 | Learning Rate: 0.001                    1.01150   \n",
       "Batch: 4 | Learning Rate: 0.0001                   0.96515   \n",
       "Batch: 8 | Learning Rate: 0.01                     1.18990   \n",
       "Batch: 8 | Learning Rate: 0.001                    1.00120   \n",
       "Batch: 8 | Learning Rate: 0.0001                   0.94756   \n",
       "\n",
       "                                              val/cls_loss  \\\n",
       "Batch: 16 | Learning Rate: 0.01                    1.34790   \n",
       "Batch: 16 | Learning Rate: 0.001                   0.67574   \n",
       "Batch: 16 | Learning Rate: 0.0001                  0.67070   \n",
       "Batch: 4 | Learning Rate: 0.01                     1.54450   \n",
       "Batch: 4 | Learning Rate: 0.001                    0.79194   \n",
       "Batch: 4 | Learning Rate: 0.0001                   0.75244   \n",
       "Batch: 8 | Learning Rate: 0.01                     1.36060   \n",
       "Batch: 8 | Learning Rate: 0.001                    0.73124   \n",
       "Batch: 8 | Learning Rate: 0.0001                   0.70645   \n",
       "\n",
       "                                              val/dfl_loss  \n",
       "Batch: 16 | Learning Rate: 0.01                     1.5252  \n",
       "Batch: 16 | Learning Rate: 0.001                    1.3317  \n",
       "Batch: 16 | Learning Rate: 0.0001                   1.2906  \n",
       "Batch: 4 | Learning Rate: 0.01                      1.5822  \n",
       "Batch: 4 | Learning Rate: 0.001                     1.4209  \n",
       "Batch: 4 | Learning Rate: 0.0001                    1.3583  \n",
       "Batch: 8 | Learning Rate: 0.01                      1.5483  \n",
       "Batch: 8 | Learning Rate: 0.001                     1.3812  \n",
       "Batch: 8 | Learning Rate: 0.0001                    1.3182  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(medium_last_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best\n",
    "  - Learning rate = 0.0001\n",
    "  - Batch = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_last_res = []\n",
    "\n",
    "for filename in os.listdir(SMALL_RES_PATH):\n",
    "    df = pd.read_csv(os.path.join(SMALL_RES_PATH, filename))\n",
    "    df = df.iloc[-1, 1:-3]\n",
    "    batch, lr = tuple(filename.split('_')[1:])\n",
    "    df.name = 'Batch: {} | Learning Rate: {}'.format(batch.split('-')[1], float(lr[3:-4]))\n",
    "    small_last_res.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train/box_loss</th>\n",
       "      <th>train/cls_loss</th>\n",
       "      <th>train/dfl_loss</th>\n",
       "      <th>metrics/precision(B)</th>\n",
       "      <th>metrics/recall(B)</th>\n",
       "      <th>metrics/mAP50(B)</th>\n",
       "      <th>metrics/mAP50-95(B)</th>\n",
       "      <th>val/box_loss</th>\n",
       "      <th>val/cls_loss</th>\n",
       "      <th>val/dfl_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Batch: 16 | Learning Rate: 0.01</th>\n",
       "      <td>1.07330</td>\n",
       "      <td>1.19010</td>\n",
       "      <td>1.4316</td>\n",
       "      <td>0.72723</td>\n",
       "      <td>0.70496</td>\n",
       "      <td>0.76973</td>\n",
       "      <td>0.53593</td>\n",
       "      <td>1.14080</td>\n",
       "      <td>1.09820</td>\n",
       "      <td>1.4735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch: 16 | Learning Rate: 0.001</th>\n",
       "      <td>0.83661</td>\n",
       "      <td>0.65344</td>\n",
       "      <td>1.2294</td>\n",
       "      <td>0.83769</td>\n",
       "      <td>0.84977</td>\n",
       "      <td>0.88712</td>\n",
       "      <td>0.66164</td>\n",
       "      <td>0.98844</td>\n",
       "      <td>0.73498</td>\n",
       "      <td>1.3274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch: 16 | Learning Rate: 0.0001</th>\n",
       "      <td>0.88369</td>\n",
       "      <td>0.82109</td>\n",
       "      <td>1.2536</td>\n",
       "      <td>0.84421</td>\n",
       "      <td>0.80270</td>\n",
       "      <td>0.86945</td>\n",
       "      <td>0.64432</td>\n",
       "      <td>0.96608</td>\n",
       "      <td>0.81940</td>\n",
       "      <td>1.2865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch: 4 | Learning Rate: 0.01</th>\n",
       "      <td>1.12420</td>\n",
       "      <td>1.52960</td>\n",
       "      <td>1.5377</td>\n",
       "      <td>0.56184</td>\n",
       "      <td>0.63356</td>\n",
       "      <td>0.63796</td>\n",
       "      <td>0.42597</td>\n",
       "      <td>1.17380</td>\n",
       "      <td>1.41920</td>\n",
       "      <td>1.5383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch: 4 | Learning Rate: 0.001</th>\n",
       "      <td>0.87446</td>\n",
       "      <td>0.78670</td>\n",
       "      <td>1.2912</td>\n",
       "      <td>0.81671</td>\n",
       "      <td>0.82784</td>\n",
       "      <td>0.85964</td>\n",
       "      <td>0.61901</td>\n",
       "      <td>1.00350</td>\n",
       "      <td>0.82910</td>\n",
       "      <td>1.3676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch: 4 | Learning Rate: 0.0001</th>\n",
       "      <td>0.92455</td>\n",
       "      <td>1.06580</td>\n",
       "      <td>1.3299</td>\n",
       "      <td>0.80132</td>\n",
       "      <td>0.75587</td>\n",
       "      <td>0.83568</td>\n",
       "      <td>0.60748</td>\n",
       "      <td>1.00430</td>\n",
       "      <td>0.95084</td>\n",
       "      <td>1.3453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch: 8 | Learning Rate: 0.01</th>\n",
       "      <td>1.10900</td>\n",
       "      <td>1.35590</td>\n",
       "      <td>1.4909</td>\n",
       "      <td>0.64275</td>\n",
       "      <td>0.68904</td>\n",
       "      <td>0.72290</td>\n",
       "      <td>0.49617</td>\n",
       "      <td>1.18090</td>\n",
       "      <td>1.22160</td>\n",
       "      <td>1.5181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch: 8 | Learning Rate: 0.001</th>\n",
       "      <td>0.85391</td>\n",
       "      <td>0.72256</td>\n",
       "      <td>1.2558</td>\n",
       "      <td>0.88494</td>\n",
       "      <td>0.79785</td>\n",
       "      <td>0.89338</td>\n",
       "      <td>0.65887</td>\n",
       "      <td>0.98851</td>\n",
       "      <td>0.74251</td>\n",
       "      <td>1.3254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch: 8 | Learning Rate: 0.0001</th>\n",
       "      <td>0.90522</td>\n",
       "      <td>0.94424</td>\n",
       "      <td>1.2918</td>\n",
       "      <td>0.81891</td>\n",
       "      <td>0.80048</td>\n",
       "      <td>0.86132</td>\n",
       "      <td>0.63745</td>\n",
       "      <td>0.98013</td>\n",
       "      <td>0.87100</td>\n",
       "      <td>1.3071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            train/box_loss  \\\n",
       "Batch: 16 | Learning Rate: 0.01                    1.07330   \n",
       "Batch: 16 | Learning Rate: 0.001                   0.83661   \n",
       "Batch: 16 | Learning Rate: 0.0001                  0.88369   \n",
       "Batch: 4 | Learning Rate: 0.01                     1.12420   \n",
       "Batch: 4 | Learning Rate: 0.001                    0.87446   \n",
       "Batch: 4 | Learning Rate: 0.0001                   0.92455   \n",
       "Batch: 8 | Learning Rate: 0.01                     1.10900   \n",
       "Batch: 8 | Learning Rate: 0.001                    0.85391   \n",
       "Batch: 8 | Learning Rate: 0.0001                   0.90522   \n",
       "\n",
       "                                            train/cls_loss  \\\n",
       "Batch: 16 | Learning Rate: 0.01                    1.19010   \n",
       "Batch: 16 | Learning Rate: 0.001                   0.65344   \n",
       "Batch: 16 | Learning Rate: 0.0001                  0.82109   \n",
       "Batch: 4 | Learning Rate: 0.01                     1.52960   \n",
       "Batch: 4 | Learning Rate: 0.001                    0.78670   \n",
       "Batch: 4 | Learning Rate: 0.0001                   1.06580   \n",
       "Batch: 8 | Learning Rate: 0.01                     1.35590   \n",
       "Batch: 8 | Learning Rate: 0.001                    0.72256   \n",
       "Batch: 8 | Learning Rate: 0.0001                   0.94424   \n",
       "\n",
       "                                            train/dfl_loss  \\\n",
       "Batch: 16 | Learning Rate: 0.01                     1.4316   \n",
       "Batch: 16 | Learning Rate: 0.001                    1.2294   \n",
       "Batch: 16 | Learning Rate: 0.0001                   1.2536   \n",
       "Batch: 4 | Learning Rate: 0.01                      1.5377   \n",
       "Batch: 4 | Learning Rate: 0.001                     1.2912   \n",
       "Batch: 4 | Learning Rate: 0.0001                    1.3299   \n",
       "Batch: 8 | Learning Rate: 0.01                      1.4909   \n",
       "Batch: 8 | Learning Rate: 0.001                     1.2558   \n",
       "Batch: 8 | Learning Rate: 0.0001                    1.2918   \n",
       "\n",
       "                                      metrics/precision(B)  \\\n",
       "Batch: 16 | Learning Rate: 0.01                    0.72723   \n",
       "Batch: 16 | Learning Rate: 0.001                   0.83769   \n",
       "Batch: 16 | Learning Rate: 0.0001                  0.84421   \n",
       "Batch: 4 | Learning Rate: 0.01                     0.56184   \n",
       "Batch: 4 | Learning Rate: 0.001                    0.81671   \n",
       "Batch: 4 | Learning Rate: 0.0001                   0.80132   \n",
       "Batch: 8 | Learning Rate: 0.01                     0.64275   \n",
       "Batch: 8 | Learning Rate: 0.001                    0.88494   \n",
       "Batch: 8 | Learning Rate: 0.0001                   0.81891   \n",
       "\n",
       "                                         metrics/recall(B)  \\\n",
       "Batch: 16 | Learning Rate: 0.01                    0.70496   \n",
       "Batch: 16 | Learning Rate: 0.001                   0.84977   \n",
       "Batch: 16 | Learning Rate: 0.0001                  0.80270   \n",
       "Batch: 4 | Learning Rate: 0.01                     0.63356   \n",
       "Batch: 4 | Learning Rate: 0.001                    0.82784   \n",
       "Batch: 4 | Learning Rate: 0.0001                   0.75587   \n",
       "Batch: 8 | Learning Rate: 0.01                     0.68904   \n",
       "Batch: 8 | Learning Rate: 0.001                    0.79785   \n",
       "Batch: 8 | Learning Rate: 0.0001                   0.80048   \n",
       "\n",
       "                                          metrics/mAP50(B)  \\\n",
       "Batch: 16 | Learning Rate: 0.01                    0.76973   \n",
       "Batch: 16 | Learning Rate: 0.001                   0.88712   \n",
       "Batch: 16 | Learning Rate: 0.0001                  0.86945   \n",
       "Batch: 4 | Learning Rate: 0.01                     0.63796   \n",
       "Batch: 4 | Learning Rate: 0.001                    0.85964   \n",
       "Batch: 4 | Learning Rate: 0.0001                   0.83568   \n",
       "Batch: 8 | Learning Rate: 0.01                     0.72290   \n",
       "Batch: 8 | Learning Rate: 0.001                    0.89338   \n",
       "Batch: 8 | Learning Rate: 0.0001                   0.86132   \n",
       "\n",
       "                                       metrics/mAP50-95(B)  \\\n",
       "Batch: 16 | Learning Rate: 0.01                    0.53593   \n",
       "Batch: 16 | Learning Rate: 0.001                   0.66164   \n",
       "Batch: 16 | Learning Rate: 0.0001                  0.64432   \n",
       "Batch: 4 | Learning Rate: 0.01                     0.42597   \n",
       "Batch: 4 | Learning Rate: 0.001                    0.61901   \n",
       "Batch: 4 | Learning Rate: 0.0001                   0.60748   \n",
       "Batch: 8 | Learning Rate: 0.01                     0.49617   \n",
       "Batch: 8 | Learning Rate: 0.001                    0.65887   \n",
       "Batch: 8 | Learning Rate: 0.0001                   0.63745   \n",
       "\n",
       "                                              val/box_loss  \\\n",
       "Batch: 16 | Learning Rate: 0.01                    1.14080   \n",
       "Batch: 16 | Learning Rate: 0.001                   0.98844   \n",
       "Batch: 16 | Learning Rate: 0.0001                  0.96608   \n",
       "Batch: 4 | Learning Rate: 0.01                     1.17380   \n",
       "Batch: 4 | Learning Rate: 0.001                    1.00350   \n",
       "Batch: 4 | Learning Rate: 0.0001                   1.00430   \n",
       "Batch: 8 | Learning Rate: 0.01                     1.18090   \n",
       "Batch: 8 | Learning Rate: 0.001                    0.98851   \n",
       "Batch: 8 | Learning Rate: 0.0001                   0.98013   \n",
       "\n",
       "                                              val/cls_loss  \\\n",
       "Batch: 16 | Learning Rate: 0.01                    1.09820   \n",
       "Batch: 16 | Learning Rate: 0.001                   0.73498   \n",
       "Batch: 16 | Learning Rate: 0.0001                  0.81940   \n",
       "Batch: 4 | Learning Rate: 0.01                     1.41920   \n",
       "Batch: 4 | Learning Rate: 0.001                    0.82910   \n",
       "Batch: 4 | Learning Rate: 0.0001                   0.95084   \n",
       "Batch: 8 | Learning Rate: 0.01                     1.22160   \n",
       "Batch: 8 | Learning Rate: 0.001                    0.74251   \n",
       "Batch: 8 | Learning Rate: 0.0001                   0.87100   \n",
       "\n",
       "                                              val/dfl_loss  \n",
       "Batch: 16 | Learning Rate: 0.01                     1.4735  \n",
       "Batch: 16 | Learning Rate: 0.001                    1.3274  \n",
       "Batch: 16 | Learning Rate: 0.0001                   1.2865  \n",
       "Batch: 4 | Learning Rate: 0.01                      1.5383  \n",
       "Batch: 4 | Learning Rate: 0.001                     1.3676  \n",
       "Batch: 4 | Learning Rate: 0.0001                    1.3453  \n",
       "Batch: 8 | Learning Rate: 0.01                      1.5181  \n",
       "Batch: 8 | Learning Rate: 0.001                     1.3254  \n",
       "Batch: 8 | Learning Rate: 0.0001                    1.3071  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(small_last_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best\n",
    "  - Learning rate = 0.001\n",
    "  - Batch = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall best is\n",
    "  - <p style=\"color: green; font-style:italic; font-weight: 800\">Model Size : Medium</p>\n",
    "  - <p style=\"color: green; font-style:italic; font-weight: 800\">Batch : 16</p>\n",
    "  - <p style=\"color: green; font-style:italic; font-weight: 800\">Learning Rate : 0.0001</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
